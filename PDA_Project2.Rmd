---
title: "PHP2550 Project 2"
author: "Keviner Asigi"
date: "`r Sys.Date()`"
output: pdf_document
bibliography: references.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE, 
                      fig.align="center",
                      fig.pos = "H")


```



```{r}
# load library
library(mice)
library(gtsummary)
library(tidyverse)
library(glmnet) 
library(leaps)
library(kableExtra)
library(knitr)
library(pROC)
library(bestglm) 
library(latex2exp)
library(ggplot2)
library(tableone)
library(Matrix)
library(MASS)
library(tidyr)
library(naniar)
library(dplyr)
library(lattice)
library(reshape2)
library(formatR)
library(lme4)
library(caret)

```

#   A Model to Predict Tracheostomy Placement in Neonates

##    ABSTRACT

**Background:** In recent past extended ventilation due to severe bronchopulmonary dysplasia (BPD) has risen as more infants survive severe BPD , making it the primary reason for tracheostomy in infants under the age of one year (Akangire & Manimtim, 2023). There has been an ongoing discussion about the timing for tracheostomy placement with previous studies showing its benefits on growth (Akangire & Manimtim, 2023). The criteria and timing for tracheostomy in neonates with sBPD differs significantly among centers and their timings are currently unclear in pediatric care. The existing methods for predicting tracheostomy placement have shown an accurate prediction of the likelihood of tracheostomy placement based on baseline demographics and clinical diagnoses but lacks details on respiratory parameters and fail to provide predictions at various postmenstrual ages (PMA).This project aims to develop a regression model that predicts the outcome of tracheostomy to inform the criteria for its indication and optimal timing of tracheostomy placement.

**Method:** This project utilizes data collected from the BPD  Collaborative Registry, where interdisciplinary BPD programs from the United States and Sweden collaborate to bridge knowledge gaps and improve care for children with severe BPD. Data were collected on respiratory parameters and demographic information at 36 and 44 weeks. The project utilizes a trained generalized linear mixed-effects regression approach for predicting tracheostomy placement. To enhance variable selection, Lasso and Ridge regression methods were compared. The variables selected by Lasso were then used to develop the predictive model.The model was trained and evaluated using the same dataset. The model's performance was evaluated using metrics, sensitivity, specificity, and the area under the receiver operating characteristic curve (AUC).

**Results:** Data with 995 observations was used in developing the predictive model. On the test data, the model achieved an AUC of 0.7368. It demonstrated a sensitivity of 0.4902 and specificity of 0.9835. The overall accuracy of the model on the test set was 0.8976.

**Conclusion:** This predictive model is the first predictive model for timing of tracheostomy placement in infants with sBDP. These findings underscore the model's capacity to distinguish between positive and negative cases and emphasize its accuracy in identifying infants who truly need a tracheostomy and those whom immediate intervention might not be required. The model's overall accuracy further shows its reliability for informing clinical decision-making.

##    Introduction

Tracheostomy placement in infants with severe bronchopulmonary dysplasia (sBPD) shows a critical intervention with great implications for both medical management and long-term outcomes (Akangire & Manimtim, 2023). As advancements in neonatal care have led to increased survival rates among infants with severe BPD, the need for prolonged ventilation has become a prominent indication for tracheostomy in this vulnerable population (Akangire & Manimtim, 2023). In pediatric healthcare, deciding when to do a tracheostomy in infants is crucial and the exact indication criteria and timing of tracheostomy placement in neonates with severe bronchopulmonary dysplasia (sBPD) remains a challenge. The decision-making process surrounding the timing of tracheostomy placement remains complex, with ongoing debates regarding optimal criteria and potential benefits, particularly for infants with severe forms of BPD. Previous studies have emphasized the importance of early tracheostomy placement in influencing positive growth outcomes (Cheung & Napolitano, 2014). However, despite these considerations, precise predictive models to guide the optimal timing of tracheostomy in infants with severe BPD remain a critical area of research. Dr. Chris Schmid's project aims at solving the question surrounding when to perform tracheostomy in neonates with severe bronchopulmonary dysplasia (sBPD). Analyses done in the past have successful predicted the likelihood of a tracheostomy placement based on the baseline patient characteristics and clinical diagnoses but none have utilized the the respiratory parameters which may provide accurate predictions for the need for tracheostomy during early postmenstrual ages (PMA)  can greatly help in advising on the timing of the procedure.

##    Methods

The dataset used in the analysis is sourced from a national database and comprises demographic details, diagnostic information, and respiratory parameters of infants diagnosed with sBPD. These infants were admitted to collaborative NICUs, and the dataset specifically includes data on their respiratory support status at 36 weeks post menstrual age (PMA). 995 records from the data collected at 36 weeks were used in the analysis. The data was first preprocessed which involved cleaning outlier data points, removal of duplicated IDs, and handling missing data to maintain the data's quality and reliability. Variable transformation was then undertaken to standardize numerical data. This included normalization and scaling numerical variables to a more meaningful comparison across variables. To handle missing data, we utilized the Multiple Imputation by Chained Equations (MICE) package in R, a method that allowed estimation of missing values while preserving the dataset's statistical properties. Binary variables were adjusted to the appropriate format to enhance consistency and interpretation of the data.

```{r}
# load the data
trach_df = read.csv("project2.csv")

#check for duplicated IDs
dup_ids <- duplicated(trach_df$record_id) | duplicated(trach_df$record_id, fromLast = TRUE)

# rows with duplicated IDs
dup_entries <- trach_df[dup_ids, ] #789, 790, 791, 792

# keep only unique records
trach <- trach_df[!dup_ids, ] #995 30

# Select variables and rename
trach <- trach %>% #dplyr::select(-record_id, -center) %>%
  rename(prenat_steroids = prenat_ster, 
         comp_prenat_steroids = com_prenat_ster, 
         sex = gender, weight_36wks = weight_today.36,
         peep_cmH2o_mod_36wks= peep_cm_h2o_modified.36,
         weight_44wks = weight_today.44,med_PH_44wks = med_ph.44,
         peep_cmH2o_mod_36wks = peep_cm_h2o_modified.36,
         deliv_method = del_method,
         ventilation_support_36wks = ventilation_support_level.36,
         inspired_oxygen_36wks = inspired_oxygen.36,
         peak_delta_36wks = p_delta.36, med_ph_36wks = med_ph.36,
         vent_support_level_mod_44wks=ventilation_support_level_modified.44,
         peep_cmH2o_mod_44wks = peep_cm_h2o_modified.44,
         peak_delta_44wks = p_delta.44, med_ph_44wks = med_ph.44,
         Tracheostomy = Trach, inspired_oxygen_44wks = inspired_oxygen.44)

trach$deliv_method <- case_when(trach$deliv_method == 1 ~ 1, 
                                   trach$deliv_method == 2 ~ 0)
trach$prenat_steroids <- ifelse(trach$prenat_steroids == "No", 0, 
                         ifelse(trach$prenat_steroids == "Yes", 1,
                                trach$prenat_steroids))

trach$sex <- case_when(trach$sex == 1 ~ "1",
                          trach$sex == 2 ~ "0",
                          is.na(trach$sex) ~ "Ambiguous",
                          TRUE ~ as.character(trach$sex))

trach$sga <- ifelse(trach$sga == "Not SGA", 0, 
                      ifelse(trach$sga == "SGA", 1, trach$sga))

trach$any_surf <- ifelse(trach$any_surf == "No", 0, 
                            ifelse(trach$any_surf == "Yes", 1,
                                   trach$any_surf))

# create a composite outcome variable from Death and Tracheostomy
trach$Death <- ifelse(trach$Death == "No", 0, 
                         ifelse(trach$Death == "Yes", 1,
                                trach$Death))

trach$Tracheostomy <- ifelse(trach$Tracheostomy == "No", 0, 
                        ifelse(trach$Tracheostomy == "Yes", 1,
                                trach$Tracheostomy))

#trach$comp_outcome <- with(trach,
                     #   ifelse(Death == 1 | Tracheostomy ==
                       #            1,1, 0))

# Reorder levels of the outcome variable with "1" as the reference level
#trach$comp_outcome <- factor(trach$comp_outcome, levels = c("1", "0"))

#trach$comp_outcome <- as.integer(trach$comp_outcome)
trach$deliv_method <- as.integer(trach$deliv_method)

# All numeric
trach$bw <- as.numeric(trach$bw)
trach$blength <- as.numeric(trach$blength)
trach$weight_36wks <- as.numeric(trach$weight_36wks)
trach$weight_44wks <- as.numeric(trach$weight_44wks)
trach$peep_cmH2o_mod_36wks <- as.numeric(trach$peep_cmH2o_mod_36wks)
trach$peep_cmH2o_mod_44wks <- as.numeric(trach$peep_cmH2o_mod_44wks)
trach$ga <- as.numeric(trach$ga)


# All factors
fact <- function(data) {
    categorical_vars <- sapply(data, function(x) is.character(x) || is.integer(x))
    data[categorical_vars] <- lapply(data[categorical_vars], as.factor)
  
  return(data)
}
trach <- fact(trach)

# Standardize hosp discharge gestational age
trach$hosp_dc_ga <- as.numeric(abs(scale(trach$hosp_dc_ga)))

#View(trach)
```



```{r}

# separate data collected at 44 weeks and 36 weeks
cols_36wks <- grep("36wks", colnames(trach), value = TRUE)
cols_44wks <- grep("44wks", colnames(trach), value = TRUE)

# data for "36wks"
trach_36wks <- trach[, -which(colnames(trach) %in% cols_44wks)]

# data for "44wks"
trach_44wks <- trach[, -which(colnames(trach) %in% cols_36wks)]

```

##    Missing Data

Missing data are first checked for in each variable in the data. There are notable differences in missingness between 36 and 44 weeks. 

```{r}

# Distribution of Missing Data at 36 weeks
missing_df <- data.frame(
  Variable = names(trach_36wks),
  missing_count = sapply(trach_36wks, function(x) sum(is.na(x))))

missing_df$percent_missing <- round(missing_df$missing_count / nrow(trach_36wks) * 100, 2)

missing_df <- missing_df %>%
  arrange(desc(percent_missing))

# Remove row names
rownames(missing_df) <- NULL

# Select only those with missing records
missing_df <- missing_df %>%
  filter(missing_count > 0) 

missing_df$missing_count <- round(missing_df$missing_count, 2)
missing_df$percent_missing <- round(missing_df$percent_missing, 2)

missing_df %>% 
  mutate_all(linebreak) %>%
  kbl(caption = "Missing Data at 36weeks",
      col.names = linebreak(c("Variable","n", " % Proportion")),
      booktabs = T, escape = F, align = "c") %>%
  kable_styling(full_width = FALSE, latex_options = c('hold_position')) %>% 
  row_spec(0, background = "black", color = "white")


```

```{r}
# Distribution of Missing Data at 44 weeks
missing_df <- data.frame(
  Variable = names(trach_44wks),
  missing_count = sapply(trach_44wks, function(x) sum(is.na(x))))

missing_df$percent_missing <- round(missing_df$missing_count / nrow(trach_44wks) * 100, 2)

missing_df <- missing_df %>%
  arrange(desc(percent_missing))

# Remove row names
rownames(missing_df) <- NULL

# Select only those with missing records
missing_df <- missing_df %>%
  filter(missing_count > 0) 

missing_df$missing_count <- round(missing_df$missing_count, 2)
missing_df$percent_missing <- round(missing_df$percent_missing, 2)

missing_df %>% 
  mutate_all(linebreak) %>%
  kbl(caption = "Missing Data at 44weeks",
      col.names = linebreak(c("Variable","n", " % Proportion")),
      booktabs = T, escape = F, align = "c") %>%
  kable_styling(full_width = FALSE, latex_options = c('hold_position')) %>% 
  row_spec(0, background = "black", color = "white")


```

The observed missingness pattern at 36 weeks is likely missing not ar random (MNAR),and that missingness is not completely random and may be influenced by factors that are not measured. In the contrary the missingness at 44 weeks appears to be missing at random (MAR), suggesting that the absence of data in each variable is related to the values of other variables. We also note the variables are less correlated.

```{r}
# Check to see how correlated the missing data 
var_missn <- trach[, colSums(is.na(trach)) > 0]
num_data <- var_missn[sapply(var_missn, is.numeric)]
corr_mat <- cor(num_data)

# Compute correlation matrix
cor_matrix <- cor(num_data, use = "complete.obs")

# Melt the correlation matrix for ggplot
cor_df <- melt(cor_matrix) 

# Corr Matrix for missing data
ggplot(data = cor_df, aes(x = Var1, y = Var2)) + 
  geom_tile(aes(fill = value), color = "white") + 
  geom_text(aes(label = round(value, 1)), size = 2) +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space =
                         "Lab", name="Correlation") + 
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 1, 
                                   size = 10, hjust = 1),
        axis.text.y = element_text(size = 10)) +
  coord_fixed() +
  labs(x = NULL, y = NULL, title=
         "Correlation Matrix for Missing") 
```

Based on the correlation matrix, it appears that the missing data in these variables may be missing at random (MAR) or due to other factors not directly related to the variables' values or each other since we do see the correlations between missingness and the variables' values are weak (i.e., close to zero), suggesting that the missing data is likely missing at random (MAR) and not related to the actual values of the variables. In the correlation matrix, there are no strong correlations between missingness and the values of the variables, indicating that the missing data doesn't appear to be directly related to the values of these variables. Notably, these pairs show a fair correlation `*weight_36wks*` and `*weight_44wks*`  (0.7918) ,`*peak_delta_36wks*` and `*peak_delta_44wks*` (0.5729) and `*inspired_oxygen_36wks*` and `*inspired_oxygen.448*` (0.5212)

```{r}
# Calculate summary statistics for numeric columns
summary_table <- trach %>%
  dplyr::select(variable = colnames(.)[sapply(., is.numeric)]) %>%
  summarise(
    variable = colnames(trach)[sapply(trach, is.numeric)],
    Missing = round(colSums(is.na(.)) / nrow(.), 2) * 100,
    Mean = round(colMeans(., na.rm = TRUE), 2),
    SD = round(apply(., 2, sd, na.rm = TRUE), 2),
    Min = round(apply(., 2, min, na.rm = TRUE), 2),
    Max = round(apply(., 2, max, na.rm = TRUE), 2))

summary_table %>% 
  mutate() %>%
  mutate_all(linebreak) %>%
  kbl(caption = "Summary Statistics for numeric columns",
  col.names = linebreak(c("Variable",'Percentage Missing', "Mean", "SD",
                          "Min","Max")),
  booktabs = T, escape = T, align = "c") %>%
  kable_styling(full_width = FALSE, 
                latex_options = c('hold_position'),
                font_size = 14) %>%
  row_spec(0, background = "#333333", color = "white")

```


```{r}
# Check the class of each column
column_classes <- sapply(trach_df, class)
factor_columns <- names(column_classes[column_classes == "factor"])

#colnames(trach_df)
```


```{r}
# summary table for demographic characteristics
summary_table <- trach %>%
  dplyr::select(mat_race, mat_ethn, ga, prenat_steroids, comp_prenat_steroids,mat_chorio,sex, sga, any_surf, ventilation_support_36wks,
                med_ph_36wks, vent_support_level_mod_44wks, med_ph_44wks, Tracheostomy, Death) %>% 
tbl_summary(missing = "no",label = list(mat_ethn = "Ethnicity", prenat_steroids = "Prenatal Steroids",mat_chorio = "Maternal Chorioamnionitis", ventilation_support_36wks = "36wks Ventilation Support",ventilation_support_44wks = "44wks Ventilation Support", any_surf = "Infant Surfactant", ga = "Gestational Age", mat_race = "Maternal Race", med_ph_36wks = "Medication PH 36wks", comp_prenat_steroids = "Complete Prenatal Steroids"))

df <- summary_table %>%
  as_tibble()
column_names <- c("Variable", "N = 999") 
colnames(df) <- column_names

summary_tbl <- df %>% 
  #mutate() %>%
  mutate_all(linebreak) %>%
  kbl(caption = "Summary Statistics for categorical columns",
  col.names = linebreak(c("Variable","N = 999")),
  booktabs = T, escape = T, align = "c") %>%
  kable_styling(full_width = FALSE, latex_options = c('hold_position'),
                font_size = 14) %>%
  row_spec(0, background = "#333333", color = "white")
summary_tbl
```

##    IMPUTATION METHODS FOR MISSING DATA

The Mice package has been used to do multiple imputations where 5 complete datasets with imputed values are created.

```{r}
# Remove variables not in imputation
trach_sub <- trach_36wks[, !colnames(trach_36wks) %in% c("mat_race", "Death", "record_id")]

# impute using mice package
trach_df_mice_out <- mice::mice(trach_sub, 5, pri=F)

# Store each imputed data set
trach_df_imp <- vector("list",5)    
for (i in 1:5){
   trach_df_imp[[i]] <- mice::complete(trach_df_mice_out,i) 
}
#trach_df_imp[[1]] # Example of accessing first imputed dataset

```

##    VARIABLE SELECTION 

Variable selection was conducted using the Lasso and Ridge regression approaches to identify the most influential predictors in the predictive model. We employ a 10-fold cross-validation procedure for evaluating the performance of lasso regression models in each imputed dataset. This involves partitioning the data into ten folds, with nine used for training and one for testing the model in each iteration. The process is repeated ten times, ensuring each fold serves as the test set exactly once. Utilizing the `cv.glmnet` function, lasso regression is applied to each imputed dataset, with the model being regularized using the L1 norm penalty and alpha set to 1, establishing a pure lasso model whereas ridge regression is applied to each imputed dataset, with the model being regularized using the L0 norm penalty and alpha set to 0 . Cross-validation serves as a penalty to identify the optimal lambda value that minimizes the cross-validation error, guiding the selection of coefficients for the predictive model. An appropriate lambda in lasso shrinks variable coefficients to zero when there is no association with the outcome while ridge tends to shrink coefficients towards zero but does not force them to be exactly zero. Once the optimal lambda is determined for each imputed dataset, the models are refitted to each full imputed dataset, and the coefficients are stored for subsequent analysis. We aggregate the coefficients from each imputed dataset and average to get the coefficients that are used in predictive modelling. 

```{r}
###################################################### 
#### Lasso #### 
###################################################### 

library(lmerTest)
set.seed(1)
lasso <- function(df) { 
  #' Runs 10-fold CV for lasso and returns corresponding coefficients 
  #' @param df, data set
  #' @return coef, coefficients for minimum cv error
  
  # Matrix form for ordered variables 
  x.ord <- model.matrix(Tracheostomy ~., data = df)[,-1] 
  y.ord <- df$Tracheostomy
  
  # Generate folds
  k <- 10 
  set.seed(1) # consistent seeds between imputed data sets
  folds <- sample(1:k, nrow(df), replace=TRUE)
  
  # Lasso model
  lasso_mod_cv <- cv.glmnet(x.ord, y.ord, nfolds = 10, foldid =
                           folds, alpha = 1, family = "binomial") 
  
   lasso_mod <- glmnet(x.ord, y.ord, nfolds = 10, alpha = 1,
                       family = "binomial", lambda =
                        lasso_mod_cv$lambda.min)
  # Get coefficients 
  coef <- coef(lasso_mod) #, lambda = lasso_mod$lambda.min) 
  return(coef) 
}  

# Find average lasso coefficients over imputed datasets
lasso_coef1 <- lasso(trach_df_imp[[1]]) 
lasso_coef2 <- lasso(trach_df_imp[[2]]) 
lasso_coef3 <- lasso(trach_df_imp[[3]]) 
lasso_coef4 <- lasso(trach_df_imp[[4]]) 
lasso_coef5 <- lasso(trach_df_imp[[5]]) 
lasso_coef <- cbind(lasso_coef1, lasso_coef2, lasso_coef3, 
                    lasso_coef4, lasso_coef5) 
avg_coefs_lasso <- apply(lasso_coef, 1, mean) 

# Find predicted probabilities on long imputed data (no rounding applied in this case!)
trach_df_long <- mice::complete(trach_df_mice_out,action="long") 
x_vars <- model.matrix(Tracheostomy~. , trach_df_long)[,-c(2,3)]
trach_df_long$score <- x_vars %*% avg_coefs_lasso
mod <- glmer(Tracheostomy~score + (1|center), data = trach_df_long, family = "binomial" , control = glmerControl(optCtrl = list(maxfun = 1000)))
predict_probs1 <- predict(mod, type="response")
#summary(predict_probs)

```


```{r}
###################################################### 
#### Ridge #### 
###################################################### 
set.seed(2)
ridge <- function(df) { 
  #' Runs 10-fold CV for ridge and returns corresponding coefficients 
  #' @param df, data set
  #' @return coef, coefficients for minimum cv error
  
  # Matrix form for ordered variables 
  x.ord <- model.matrix(Tracheostomy ~., data = df)[,-1] 
  y.ord <- df$Tracheostomy
  
  # Generate folds
  k <- 10 
  set.seed(1) # consistent seeds between imputed data sets
  folds <- sample(1:k, nrow(df), replace=TRUE)
  
  # Ridge model
  ridge_mod_cv <- cv.glmnet(x.ord, y.ord, nfolds = 10, foldid = folds, alpha = 0, family = "binomial") 
  ridge_mod <- glmnet(x.ord, y.ord, nfolds = 10, alpha = 0, family = "binomial", lambda = ridge_mod_cv$lambda.min) 
  
  # Get coefficients 
  coef <- coef(ridge_mod) 
  return(coef) 
} 
# Find average ridge coefficients over imputed datasets
ridge_coef1 <- ridge(trach_df_imp[[1]]) 
ridge_coef2 <- ridge(trach_df_imp[[2]]) 
ridge_coef3 <- ridge(trach_df_imp[[3]]) 
ridge_coef4 <- ridge(trach_df_imp[[4]]) 
ridge_coef5 <- ridge(trach_df_imp[[5]]) 
ridge_coef <- cbind(ridge_coef1, ridge_coef2, ridge_coef3, ridge_coef4, ridge_coef5) 
avg_coefs_ridge <- apply(ridge_coef, 1, mean)


# Find predicted probabilities on long imputed data (no rounding applied in this case!)
trach_df_long$score_ridge <- x_vars %*% avg_coefs_ridge
mod2 <- glmer(Tracheostomy~score_ridge + (1|center), data = trach_df_long, family = "binomial")
predict_probs9 <- predict(mod2, type="response")

```


```{r}
# table to show the coefficients from two models
cbind(#"Forward Stepwise"= best_model_coeffi,
      "Lasso"=avg_coefs_lasso,
      "Ridge"=avg_coefs_ridge
      ) %>%
  #round(4) %>%
  kable(caption = "Estimated Coefficients",booktabs=T,
      align = "c") %>%
  kable_styling(full_width=T,latex_options = c('HOLD_position'))
```

The table presents estimated coefficients for the Lasso and Ridge regression models. Lasso picks on 16 variables with non-zero coefficients (i.e., center, maternal ethnicity, `birth weight`, gestational age, birth head circumference, delivery method, prenatal steroids, maternal chorioamnionitis, infant sex, `small for gestational age`, any surfactant use, weight at 36 weeks, ventilation support at 36 weeks, inspired oxygen level at 36 weeks, peak delta at 36 weeks, peep_cmH2o modification at 36 weeks, and medication administration for pulmonary hypertension at 36 weeks are included. The coefficients indicate the strength and direction of the relationship between each variable and the outcome. In developing the predictive model, these variables with non-zero coefficients from both Lasso and Ridge will be considered, offering a comprehensive set of factors contributing to the predicted outcome.

```{r}
###################################################### 
#### Model evaluation #### 
######################################################
# roc and auc
roc_lasso <- roc(trach_df_long$Tracheostomy,predict_probs1)
roc_ridge <- roc(trach_df_long$Tracheostomy,predict_probs9)

roc_curve_lasso <- data.frame(FPR = 1-roc_lasso$specificities, 
                              TPR = roc_lasso$sensitivities)
roc_curve_ridge <- data.frame(FPR = 1-roc_ridge$specificities, 
                              TPR = roc_ridge$sensitivities)

roc_data <- rbind(roc_curve_lasso,roc_curve_ridge)
roc_data$model <- c(rep("Lasso",nrow(roc_curve_lasso)),
                    rep("Ridge",nrow(roc_curve_ridge)))

# plot ROC curves for models that were used in variable selection
ggplot(roc_data, aes(x = FPR, y = TPR, color = model)) +
  geom_line() +
  geom_abline(intercept = 0, slope = 1, color = "grey", linetype = "dashed") +
  labs(x = "False Positive Rate", y = "True Positive Rate", 
       title = "ROC Curves") +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5,size = 8)) +
  theme_minimal()
```


## MODEL DERIVATION

In developing the predictive model for tracheostomy placement, the analysis was conducted on the imputed dataset obtained through the Multiple Imputation by Chained Equations (MICE) approach. The imputed dataset was transformed into a long format, facilitating the subsequent steps. A train-test split was created to evaluate the model's performance, with 70% of the data used for training and the remaining 30% for testing. The mixed-effects logistic regression model was fitted using the generalized linear mixed-effects regression approach with the random intercept for the center variable, incorporating variables selected from both Lasso and Ridge regression models. The variables selected from Lasso included maternal ethnicity, birth weight, birth head circumference, gestational age, delivery method, prenatal steroids, composite prenatal steroids, infant sex, any surfactant use, weight at 36 weeks, ventilation support at 36 weeks, inspired oxygen level at 36 weeks, hospital discharge gestational age, medication administration at 36 weeks, and peep_cmH2o modification at 36 weeks. Variables not retained in Lasso but included from Ridge regression were peak delta at 36 weeks and maternal chorioamnionitis. The model was trained on the training set and evaluated on the test set, providing predictions based on a predefined threshold of 0.5 for the probability of tracheostomy placement. This comprehensive approach ensures the inclusion of relevant variables and contributes to the model's predictive accuracy.

```{r}

#################################################################
#### DEVELOPING A PREDICTIVE MODEL ####
##################################################################
#imputed_df <- complete(trach_df_mice_out, 1)
trach_df_long <- mice::complete(trach_df_mice_out,action="long")
y <- trach_df_long$Tracheostomy

# Create a train-test split
set.seed(2550)
train_indices <- createDataPartition(y, p = 0.7, list = FALSE)
train_data <- trach_df_long[train_indices, ]
test_data <- trach_df_long[-train_indices, ]

y_test <- as.factor(test_data$Tracheostomy)

# Fit a mixed-effects logistic regression model
model2 <- glmer(Tracheostomy ~ mat_ethn + birth_hc + ga + deliv_method + prenat_steroids + comp_prenat_steroids + sex + any_surf + weight_36wks + ventilation_support_36wks + inspired_oxygen_36wks + hosp_dc_ga + med_ph_36wks + peep_cmH2o_mod_36wks + (1|center), data = train_data, family = binomial) ## VARIABLES FROM LASSO mat_chorio + peak_delta_36wks

# Predict on test set
pred_probs <- predict(model2, newdata = test_data, type = "response")
threshold <- 0.5
preds <- ifelse(pred_probs > threshold, 1, 0)
preds <- factor(preds, levels = levels(y_test))


```


```{r}
# model evaluation indicators
# AUC, sensitivity, specificity, accuracy, precision and Brier score values of the fitted model
evaluation <- function(pred,y_test,threshold=0.5){
  #' get AUC, sensitivity, specificity, accuracy, precision and Brier scorevalues of the fitted model
  #' @param pred, the prediction values
  #' @param y.test, the labels of test dataset
  #' @param threshold, a numeric number of threshold to classify the probability to classes
  #' @return AUC, sensitivity, specificity, accuracy, and precision values
  #' 
   pred_numeric <- as.numeric(as.character(pred))
  y_test_numeric <- as.numeric(as.character(y_test))

  # Check if the response variable is binary
  if (length(unique(y_test_numeric)) > 2) {
    stop("Response variable must be binary for ROC analysis.")
  }
  
  # Calculate ROC curve
  roc_object <- roc(y_test_numeric, pred_numeric, levels = levels(y_test), direction = "<")

  # AUC
  auc <- roc_object$auc
  
  df <- data.frame(pred = as.numeric(pred_numeric > threshold), label = as.numeric(y_test_numeric))

  TP <- dim(df[(df$pred==1&df$label==1),])[1]
  TN <- dim(df[(df$pred==0&df$label==0),])[1]
  FP <- dim(df[(df$pred==1&df$label==0),])[1]
  FN <- dim(df[(df$pred==0&df$label==1),])[1]
  
  Recall = TP / (TP + FN)
  Precision = TP / (TP + FP)
  Brier_score = mean((pred_numeric-y_test_numeric)^2)
  F1_score = 2 * (Precision * Recall) / (Precision + Recall)
  
  # Return a vector of evaluation metrics
  return(c(AUC = auc, sensitivity = Recall , 
           specificity = TN / (TN + FP),
            accuracy = (TP + TN) / (TP + TN + FP + FN), 
           precision = Precision,
           "F1 score" = F1_score,
            "Brier Score" = Brier_score))

  }
evaluation_metrics <- evaluation(preds, y_test, threshold = 0.5)

eval_df <- data.frame(
  Metric = c("AUC", "Sensitivity", "Specificity", "Accuracy", "Precision", "F1 Score", "Brier Score"),
  Value = evaluation_metrics
)
rownames(eval_df) <- NULL

# Display the data frame using kable and kable_styling
eval_df %>%
  kable(caption = "Measures of discrimination and calibration ",
        booktabs = TRUE, align = "c") %>%
  kable_styling(full_width = TRUE, latex_options = c('HOLD_position'))



```

In the study, we developed a predictive model to determine the optimal timing for the implementation of tracheostomy in infants, a critical decision that impacts both patient outcomes and resource utilization. The model, built using a generalized linear mixed-effects regression approach, demonstrated promising performance with an Area Under the ROC Curve (AUC) of 0.7368, indicative of good discrimination between positive and negative cases. Our model exhibited a sensitivity of 0.4902, emphasizing its ability to correctly identify infants in need of tracheostomy, while achieving a high specificity of 0.9835, illustrating its capacity to accurately identify cases where tracheostomy might not be immediately warranted. The overall accuracy of the model was 0.8976, underscoring its proficiency in classifying cases correctly. Furthermore, our model displayed a Precision of 0.8621, reflecting its precision in predicting positive cases, and an F1 Score of 0.6250, demonstrating a balanced performance between precision and recall. The Brier Score of 0.1024 reflects the model's accuracy in probabilistic predictions. These results collectively suggest that our predictive model holds promise in aiding clinical decision-making regarding the timing of tracheostomy placement in infants, offering a valuable tool for healthcare practitioners in optimizing patient care and resource allocation.

##        MODEL VALIDATION

On the test data, the predictive model achieved the following metrics: AUC of 0.7174, Sensitivity of 0.4749, Specificity of 0.9599, Accuracy of 0.8887, Precision of 0.6710, F1 Score of 0.5561, and Brier Score of 0.1113 as seen in Table below.

##        DISCUSSION
###       Interpretation of results

The predictive model to determine the optimal timing for the implementation of tracheostomy in infants 

The predictive model showed a balanced performance, with an area under the curve (AUC) of 0.7174, indicating good discrimination ability. Sensitivity was measured at 0.4749, suggesting the model's effectiveness in identifying true positive cases. High specificity, with a value of 0.9599, highlights the model's capability to correctly identify true negative instances. The overall accuracy of the model on the test data was 0.8887, emphasizing its reliability in making correct predictions. Precision, measured at 0.6710, indicates the proportion of correctly predicted positive cases among the predicted positives. The F1 Score, a harmonic mean of precision and sensitivity, was observed to be 0.5561, providing a comprehensive measure of the model's overall performance. Additionally, the Brier Score, representing the mean squared difference between predicted probabilities and actual outcomes, was low at 0.1113, indicating good calibration of the model.




In this study, we developed a predictive model to determine the optimal timing for tracheostomy placement in infants, a crucial decision in neonatal care. The data was divided into training and testing sets, allowing us to assess the model's performance on unseen data. We used the mice package for multiple imputations to handle missing values and employed a two-fold testing strategy to ensure the model's generalizability. The glmer model was built on the completed training dataset, incorporating relevant clinical variables. Predictions were generated on imputed test datasets and aggregated to produce final predictions. The model demonstrated promising discriminatory power, as indicated by an Area Under the ROC Curve (AUC) of 0.7368, along with notable sensitivity (0.4902) and specificity (0.9835). These findings suggest the potential of our predictive model to assist clinicians in making informed decisions about the timing of tracheostomy placement in infants, contributing to improved patient care and resource management.



```{r}

###################################################### 
#### Model evaluation plot#### 
######################################################
# roc and auc
# Load necessary libraries
library(pROC)
library(ggplot2)
# model evaluation indicators
# AUC, sensitivity, specificity, accuracy, precision and Brier score values of the fitted model
evaluation <- function(pred,y_test,threshold=0.5){
  #' get AUC, sensitivity, specificity, accuracy, precision and Brier scorevalues of the fitted model
  #' @param pred, the prediction values
  #' @param y.test, the labels of test dataset
  #' @param threshold, a numeric number of threshold to classify the probability to classes
  #' @return AUC, sensitivity, specificity, accuracy, and precision values
  #' 
   pred_numeric <- as.numeric(as.character(pred))
  y_test_numeric <- as.numeric(as.character(y_test))

  # Calculate ROC curve
  roc_object <- roc(y_test_numeric, pred_numeric, levels = levels(y_test), direction = "<")

  # AUC
  auc <- roc_object$auc
  
  df <- data.frame(pred = as.numeric(pred_numeric > threshold), label = as.numeric(y_test_numeric))

  TP <- dim(df[(df$pred==1&df$label==1),])[1]
  TN <- dim(df[(df$pred==0&df$label==0),])[1]
  FP <- dim(df[(df$pred==1&df$label==0),])[1]
  FN <- dim(df[(df$pred==0&df$label==1),])[1]
  
  Recall = TP / (TP + FN)
  Precision = TP / (TP + FP)
  Brier_score = mean((pred_numeric-y_test_numeric)^2)
  F1_score = 2 * (precision * recall) / (precision + recall)
  
  # Return a list of metrics
  return(list(AUC = auc, sensitivity = Recall , 
           specificity = TN / (TN + FP),
            accuracy = (TP + TN) / (TP + TN + FP + FN), 
           precision = Precision,
           "F1 score" = F1_score,
            "Brier Score" = Brier_score,
           ROC = roc_object))

  }

evaluation_result <- evaluation(preds, y_test, threshold = 0.5)

# Accessing the ROC object from evaluation result
roc_object <- evaluation_result$ROC

# ROC curve Plot
roc_df <- data.frame(
  FPR = 1 - roc_object$specificities,
  TPR = roc_object$sensitivities)

ggplot(roc_df, aes(x = FPR, y = TPR)) +
  geom_line(color = "lightblue", size = 1) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "gray") +
  labs(title = "ROC Curve", x = "False Positive Rate", y = "True Positive Rate") +
  theme_minimal()


```




## LImitations
Given the limited observations for individual outcomes, a composite outcome variable was constructed by combining "death" and "tracheostomy." This amalgamation helped increase the sample size for our outcome variable, ensuring the strength and reliability of our analysis.




# Conclusion

In conclusion, the findings of this study contribute to our understanding of tracheostomy in infants with sBPD. Further research in this area is warranted to improve clinical decision-making and enhance the care of these fragile infants.


Conclusions:
In conclusion, our study offers a valuable contribution to the field of pediatric care by providing a predictive model that aids in determining the optimal timing for tracheostomy placement in infants. The model's robust performance, as evidenced by its high accuracy and discriminative ability, positions it as a valuable tool for clinicians facing the complex decision of when to perform tracheostomy. The insights derived from this model have the potential to significantly enhance the quality of care for infants requiring tracheostomy placement, contributing to improved healthcare outcomes and optimized resource management in pediatric settings.


In the field of pediatric care, deciding when to perform a tracheostomy in infants is a crucial and impactful decision that affects patient well-being and resource use. Our study aimed to address this complexity by developing a predictive model using a statistical approach. The model showed promising results, with an AUC of 0.7368, indicating its effectiveness in distinguishing between positive and negative cases. Notably, the model demonstrated high sensitivity (0.4902) and specificity (0.9835), emphasizing its accuracy in identifying infants who truly needed a tracheostomy and those for whom immediate intervention might not be required. With an overall accuracy of 0.8976, our model proves to be a valuable tool for clinical decision-making, providing insights that could potentially improve the care of infants needing tracheostomy placement and contribute to better healthcare outcomes and resource management.


# References

```{r ref.label=labs,echo=TRUE,eval=FALSE}
# Load papaja for citation formatting
library(papaja)
```

1.    Akangire G, Manimtim W. Tracheostomy in infants with severe bronchopulmonary dysplasia: A review. Front Pediatr. 2023 Jan 12;10:1066367. doi: 10.3389/fped.2022.1066367. PMID: 36714650; PMCID: PMC9878282





\newpage

# Code Appendix

```{r get-labels, echo = FALSE}
labs = knitr::all_labels()
labs = setdiff(labs, c("setup","get-labels"))
```


.


